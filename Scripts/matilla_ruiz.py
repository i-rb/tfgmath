# -*- coding: utf-8 -*-
"""Matilla_Ruiz.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DRzGkx6cG7PYtbQAVat0RZhdLXVxOrVr

# Implementaciones Test de Caos SSTT
"""

2+2

rr=np.read_csv("IBM.csv")

rr.head()

"""### **Índice**

* 1. Test Basado en la Entropía
  - 1.1. Construcción del test
  - 1.2. Pruebas del Test Basado en la Entropía
"""

# some imports

import numpy as np
import pandas as pd
import random as rd
import matplotlib.pyplot as plt
rd.seed(985132456) # set seed
import seaborn as sns
sns.set_style("darkgrid")
from itertools import permutations
import math as mt
from sklearn.linear_model import LinearRegression
from sklearn import metrics
import statsmodels.api as sm
from scipy.stats import t
import datetime as dt

# funcion para la hora
def hora():
    now = dt.datetime.now()
    dt_string = now.strftime("%d/%m/%Y %H:%M:%S")
    print("                                                       ", dt_string)

"""Se trata de conseguir una función que, dado como input una serie temporal en formato array, devuelva como output si es **determinista o estocástica**.

## 1. Test basado en la entropía.

Link al paper [aquí](https://www.sciencedirect.com/science/article/abs/pii/S0167268110001964).

La función final se denomina _**test_entropia(ts,w,m,alpha)**_ y se explica a lo largo del cuaderno.

### 1.1. Construcción del test.
"""

def S(m): # devuelve el conjunto simétrico de permutaciones de parámetro m
          # como string en lista
  string_ini=""
  for i in range(m):
    string_ini=string_ini+str(i)
  S=[]
  return [''.join(p) for p in permutations(string_ini)]

# e.g. S(3)
S(3)

# parameters
def parameters(w,m): # a partir de w y m se tienen los demás parámetros, pero
                     # han de ser enteros etc
  m_f=mt.factorial(m)
  k=m_f/w
  if (k==int(k))&(w<0.25*m_f): # w<<m! (a razón de 0.25)
    return w, m, m_f, k
  else:
    print("ERROR")
    if k!=int(k):
        print("Tipo I: Escoja otro parámetro w o m tq k=m!/w sea entero")
    if w>0.25*m_f:
        print("Tipo II: Escoja otro parámetro w o m tq w<<m!")
    return -1

# e.g. (valid)
parameters(w=5,m=5)

# e.g. (not valid tipo I)
parameters(w=5,m=4)

# e.g. (not valid tipo II)
parameters(w=6,m=3)

# e.g. (not valid tipo I y II)
parameters(w=5,m=2)

"""Construimos la serie $W_1,W_2,...,W_k$"""

def Warray(w,m): # a partir de w y m, obteniendo w, m, m!, k
  if parameters(w,m)==-1:
    print("Mala elección de los parámetros.")
  w, m, m_f, k = parameters(w,m)
  s=S(m)
  Wi_1=rd.sample(s,w)
  for i in Wi_1:
    s.remove(i)
  W=[Wi_1]
  for i in range(int(k)-1):
    Wi=rd.sample(s,w)
    W.append(Wi)
    for j in Wi:
      s.remove(j)
    Wi_1=Wi 
  i=1
  while i<len(W):
    W[i]=W[i]+W[i-1]
    i=i+1
  return W

"""> _Now we define the next **modified** permutation entropy's function:_

> $h^{W_j}(m)=-\sum_{\pi_i \in W_j} p(\pi_i)\log p(\pi_i)$

and...

> $p(\pi)=\dfrac{\#\{t:t\in[0,T-(m-1)],\mathbf{x}_m(t)\,has\,type\,\pi\}}{T-(m-1)}$
"""

def p(ts,pi): # given ts returns p for π (str)
  T=len(ts)
  m=len(pi)
  t=0
  card=0
  piarray=list(pi)
  ac=[]
  for i in piarray:
    ac.append(int(i))
  ac=np.array(ac)
  while t<T-(m-1):
    l=ts[t:t+m]
    order=np.unique(l,return_index=True)[1]
    if np.array_equal(order,ac):
      card=card+1
    t=t+1
  return card/(T-(m-1))

def h_wj_m(ts,Wj): # from the time serie (ts), Wj in W and m return h_wj_m
  hwjm=[]
  suma=0
  for pi in Wj:
    try:
      suma=suma+p(ts,pi)*mt.log(p(ts,pi))
    except:
      suma=suma
  return -suma

def seq_h(ts,w,m): # definimos sucesion {h(wj)(m)}j=1...k
    W=Warray(w,m)
    seqh=[]
    for i in W:
      seqh.append(h_wj_m(ts,i))
    return seqh

"""> **Theorem 1.** Let $\{X_t\}_{t\in I}$ be a real stationary time series and $m$ a fixed embedding dimension. Then one of the following conditions holds:
> 
> 1. $\{X_t\}_{t\in I}$ is non-deterministic (i.e.,stochastic) and $h^{W_j}(m)<h^{W_{j+1}}(m)$$\;\;\;\forall j=1,2,...,k$
>
> 2. $\{X_t\}_{t\in I}$ is deterministic and exits $j_0$ such that $h^{W_j}(m)=h^{W_{j_0}}(m)$$\;\;\;\forall j\in[j_0,k]$

**NUMERICAL SLOPE and its TEST**

> Let $dh^{W_j}(m)$ denotes the numerical slope of $h^{Wj}(m)$, that is:
> 
> $dh^{Wj}(m)=\dfrac{h^W_{j+1}(m)−h^{j(m)}}{\log((j+1)/j)}$

> **According to Theorem 1and its scaling behavior, the numerical slope of permutation entropy of a random process will increase with $\log(jw)$, while this will not hold for chaotic or regular processes.**

> This property of the numerical slope of $h^{W_j}(m)$ can be tested using a classical econometric test (OLS estimators) by performing the following regression:
> 
> $dh^{W_j}(m)=\alpha_0+\alpha_1j+\varepsilon_j, \;\;\forall j=1,...,k-1$

> Thus, we can test determinism by testing:

> $H_0:\alpha_1=0\;(deterministic\;process)$

> $H_1:\alpha_1>0\;(stochastic\;process)$

Primero debemos definir la serie $dh^{W_j}(m)$ para cada j.
"""

def dhwjm(hwjm): #hwjm, serie de hwj(m) para cada j
  ac=[]
  j=1
  while j<len(hwjm)-1:
    valor=(hwjm[j]-hwjm[j-1])/(mt.log((j+1)/j))
    ac.append(valor)
    j=j+1
  return ac

def test(valor,se,df,alpha): # test para contrastar H0 vs H1 (df=n-2)
                             # params: valor estadistico, standard error, grados
                             # de libertad, significacion
  T=valor/se
  print(" . . Valor del estadístico T : "+str(T))

  p=(t.cdf(T,df))
  pext=t.ppf(1-alpha, df)
  pvalor=1-p
  print(" . . p-valor                 : "+str(pvalor))
  if T>pext:
    print()
    print("RESULTADO:  Proceso Estocástico")
    print()
    return True

  else:
    print()
    print("RESULTADO:  Proceso Determinista")
    print()
    return False

"""Ahora, una vez que tenemos la serie y el test, creamos una función que, dada la serie a testear, nos diga si viene de un proceso determinista o estocástico. Es nuesta **función principal**. La llamamos:

  * _test_entropia(time_serie, w=5, m=5, alpha=0.05)_

Siendo w y m los parámetros y alpha la significacón del test. El output nos devuelve True si es estocástico y False si es determinista y se imprimen algunas características del proceso.
"""

def test_entropia(ts,w=5,m=5,alpha=0.05):
  print("##################################")
  print("#   Test basado en la entropía   #")
  print("##################################")
  print()
  hora()
  print("Comienza el cálculo...")

  hh=seq_h(ts,w,m)
  y=np.array(dhwjm(hh))
  x1=np.array(list(range(1,len(y)+1)))
  x=sm.add_constant(x1)
  ols = sm.OLS(y,x)
  ols_result = ols.fit()
  intercept=ols_result.params[0]
  slope=ols_result.params[1]
  ses=ols_result.HC0_se
  print()
  print("Constante (alpha_0): "+str(intercept)+", con d.t.: "+str(ses[0]))
  print("Pendiente (alpha_1): "+str(slope)+", con d.t.: "+str(ses[1]))
  print()
  res=ols_result.predict(x)
  print()
  print("Resultado de la regresión: ")
  print()
  ax=sns.lineplot(x1,res,label="Predicted (alpha_0+alpha_1*j)")
  ax=sns.scatterplot(x1,y,color="darkred",label="Observed (dhwjm)")
  ax.set_title("Regresión de dhwj sobre j")
  ax.set(xlabel='j', ylabel='dhwj')
  plt.show()
  print()
  res=test(slope,ses[1],len(x)+2,alpha)
  hora()
  print()
  return res

"""### 1.2. Pruebas del Test Basado en la Entropía

Para probar el test, simulamos la serie del modelo de caos logístico:
* $y(t)=4y_{t-1}*(1-y_{t-1})$ con $y_0=0.7$ y $t=1,...,600$
"""

# logistic chaotic model
ac=[0.7]
for i in range(600):
  ac.append(4*ac[i]*(1-ac[i]))
serie_log=np.array(ac)
ax=sns.lineplot(range(len(serie_log[0:100])),serie_log[0:100]);
ax.set_title("Primeras 100 observaciones de la serie Logistica")
ax.set(xlabel="t",ylabel="y(t)");

"""Asimismo, simulamos una serie $y_t$ proveniente de una muestra de una normal $N(0,1)$."""

# N(0,1)
ac=[]
for i in range(500):
  ac.append(np.random.normal())
serie_nor=np.array(ac)
ax=sns.lineplot(range(len(serie_nor[0:100])),serie_nor[0:100]);
ax.set_title("Primeras 100 observaciones de la serie Normal")
ax.set(xlabel="t",ylabel="y(t)");

test_entropia(serie_log,alpha=0.2,w=5,m=5)

test_entropia(serie_nor,w=5,m=5)

"""Así, se muestra que la primera viene determinada por un **proceso determinista**, mientras la segunda por un **proceso estocástico**."""